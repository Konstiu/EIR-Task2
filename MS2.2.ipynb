{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2ccad7-33bd-44b8-abb3-a0517c683e88",
   "metadata": {},
   "source": [
    "# MS 2.2- Group 10\n",
    "\n",
    "**Members**: Niklas GrÃ¼ner (12217059), Konstantin Unterweger (12222169), Martin Harhammer (12221683)\n",
    "\n",
    "\n",
    "This notebook presents our implementation for Milestone 2.2. We built upon the foundation of our work in Milestone 2.1, reusing key components such as file loading, spectrogram computation, and the generation of constellation maps. Expanding on this groundwork, we have now implemented an audio identification system using the fingerprinting technique.\n",
    "\n",
    "In this implementation, we focus on selecting anchor points and defining corresponding target zones from the peaks of the constellation map. We then compute the hashes and store them in a dictionary for efficient matching. To validate our approach, we experimented with four different configurations. We first conducted small-scale tests using the dataset from Milestone 2.1 and then extended our evaluation with an additional 60 tarballs (=34 thousand songs)\n",
    "\n",
    "At the end of this notebook, you will find detailed visualizations, evaluations, and a comprehensive discussion of our thought process, results, and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f54f9-5a1c-422d-a1b0-4a724d15679b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d41eb8e-5435-4235-be1c-2d82cf56a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import time\n",
    "\n",
    "sys.path.append('..')\n",
    "import libfmp.b\n",
    "import libfmp.c2\n",
    "import libfmp.c6\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a404e0-ae94-4a93-90f6-1cb6f5d912ce",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "In this section, we define all the necessary functions for computing spectrograms, generating constellation maps, calculating hashes, and performing hash matching. The functions for loading audio files, spectrogram computation, and generating constellation maps are reused from Milestone 2.1.\n",
    "\n",
    "New additions include functions for defining target zones, identifying points within those zones, computing hashes, building the hash database, and matching hashes. We also introduce functions to evaluate the consistency of offsets during the matching process. These new functionalities are central to implementing the audio fingerprinting technique in this milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37de749-9b67-444b-b8c0-51dd0c3b3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filenames(directory):\n",
    "    filenames = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Create the full path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if it is a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Add to the dictionary, using the filename as the key\n",
    "            filenames.append(file_path)\n",
    "\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be51cd-37ad-44c7-b167-93aee40bbe5a",
   "metadata": {},
   "source": [
    "### Spectrogram\n",
    "This function is responsible for computing the spectrogram map of a given track. We limit the track duration that is used to 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef06df91-9bc6-41cb-81ef-cd227c10a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectrogram(fn_wav, Fs=22050, N=2048, H=1024, bin_max=128, frame_max=None, duration=None):\n",
    "    x, Fs = librosa.load(fn_wav, sr=Fs)\n",
    "    x_duration = len(x) / Fs\n",
    "    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann')\n",
    "    if bin_max is None:\n",
    "        bin_max = X.shape[0]\n",
    "    if frame_max is None:\n",
    "        frame_max = X.shape[0]\n",
    "    Y = np.abs(X[:bin_max, :frame_max])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295f99b-d59e-4dea-8a8f-fa6050b768c3",
   "metadata": {},
   "source": [
    "### Constellation map \n",
    "This function computes the constellation map, given a spectrogram map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2700908-b75b-40c3-8248-156855ceebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constellation_map(Y, dist_freq=7, dist_time=7, thresh=0.01):\n",
    "    \"\"\"Compute constellation map (implementation using image processing)\n",
    "\n",
    "    Notebook: C7/C7S1_AudioIdentification.ipynb\n",
    "\n",
    "    Args:\n",
    "        Y (np.ndarray): Spectrogram (magnitude)\n",
    "        dist_freq (int): Neighborhood parameter for frequency direction (kappa) (Default value = 7)\n",
    "        dist_time (int): Neighborhood parameter for time direction (tau) (Default value = 7)\n",
    "        thresh (float): Threshold parameter for minimal peak magnitude (Default value = 0.01)\n",
    "\n",
    "    Returns:\n",
    "        Cmap (np.ndarray): Boolean mask for peak structure (same size as Y)\n",
    "    \"\"\"\n",
    "    result = ndimage.maximum_filter(Y, size=[2*dist_freq+1, 2*dist_time+1], mode='constant')\n",
    "    Cmap = np.logical_and(Y == result, result > thresh)\n",
    "    return Cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530cacda-d4b4-4302-aa6c-1dc2ea160662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute_constellation_map_single(args):\n",
    "    \"\"\"Compute the constellation map for a single file.\"\"\"\n",
    "    filename, dist_freq, dist_time = args\n",
    "    spectrogram = compute_spectrogram(filename)  # Perform I/O and computation\n",
    "    constellation_map = compute_constellation_map(spectrogram, dist_freq, dist_time)\n",
    "    return filename, constellation_map\n",
    "\n",
    "def compute_constellation_maps(filenames, dist_freq, dist_time):\n",
    "    \"\"\"Compute constellation maps using multithreading.\"\"\"\n",
    "    # Prepare arguments for each file\n",
    "    args = [(filename, dist_freq, dist_time) for filename in filenames]\n",
    "    \n",
    "    # Use ThreadPoolExecutor for multithreading\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(compute_constellation_map_single, args)\n",
    "    \n",
    "    # Convert results to a dictionary\n",
    "    Cmaps = dict(results)\n",
    "    return Cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa3ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e7447-9f7a-4556-937b-45f44d4d87fa",
   "metadata": {},
   "source": [
    "## Computing hashes for a single audio track\n",
    "\n",
    "This function processes an audio file to compute robust hashes based on its spectrogram. \n",
    "\n",
    "**Arguments:**\n",
    "- `filename (str)`: Path to the audio file.\n",
    "- `dist_freq (int), dist_time (int)`: Neighborhood size parameters for frequency and time directions.\n",
    "- `time_min_offset, time_max_offset, freq_min_offset, freq_max_offset`: Bounds defining the \"target zone\" around an anchor point.\n",
    "\n",
    "**Returns:**\n",
    "A list of tuples `(hash, track_name, time_offset)`:\n",
    "- `hash`: A unique value based on anchor-target pairs.\n",
    "- `track_name`: A numeric ID extracted from the filename.\n",
    "- `time_offset`: The time coordinate of the anchor point.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Spectrogram and Constellation Map**: We compute the spectrogram from the audio file and generate a constellation map using the neighborhood parameters.\n",
    "2. **Sorting Points**: The points are sorted by their time coordinate to make retrieving target zone points more efficient, allowing us to stop the search early when no further points can be within the bounds.\n",
    "3. **Hash Computation**: For each anchor point, we compute hashes for its target zone points and add them to the result.\n",
    "4. **Memory Management**: To handle large datasets, we periodically clear memory and print progress after every 1000 tracks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bc56ad-2af7-49df-baa3-f4adfc094d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_hashes_from_spectrogram(filename, dist_freq, dist_time, \n",
    "                                    time_min_offset, time_max_offset, \n",
    "                                    freq_min_offset, freq_max_offset):\n",
    "    \"\"\"\n",
    "    Compute hashes for a single track directly from its spectrogram.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the audio file.\n",
    "        dist_freq (int): Neighborhood parameter for frequency direction.\n",
    "        dist_time (int): Neighborhood parameter for time direction.\n",
    "        time_min_offset, time_max_offset, freq_min_offset, freq_max_offset (int): \n",
    "            Bounds for the \"target zone\" around an anchor point.\n",
    "\n",
    "    Returns:\n",
    "        list: [(hash, track_name, time_offset), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    global count\n",
    "    global count2\n",
    "    spectrogram = compute_spectrogram(filename)\n",
    "    cmap = compute_constellation_map(spectrogram, dist_freq, dist_time)\n",
    "    \n",
    "    # Convert the boolean map to a list of points (freq, time), sorted by time\n",
    "    point_list = sorted(np.argwhere(cmap).tolist(), key=lambda x: x[1])\n",
    "    hashes = []\n",
    "    del cmap\n",
    "    del spectrogram\n",
    "    \n",
    "    for anchor in point_list:\n",
    "        target_points = get_target_zone_points(\n",
    "            anchor, \n",
    "            point_list,\n",
    "            time_min_offset=time_min_offset,\n",
    "            time_max_offset=time_max_offset,\n",
    "            freq_min_offset=freq_min_offset,\n",
    "            freq_max_offset=freq_max_offset\n",
    "        )\n",
    "        for target_point in target_points:\n",
    "            h = compute_hash(anchor, target_point)\n",
    "            hashes.append((h, int(extract_numeric_id(filename)), anchor[1]))\n",
    "    \n",
    "    count += 1\n",
    "    count2 += 1\n",
    "    if (count % 1000) == 0:\n",
    "        gc.collect()\n",
    "        print(f\"Processed {count} tracks\")\n",
    "\n",
    "    return hashes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd6224-1e4f-476d-b04d-700929731d73",
   "metadata": {},
   "source": [
    "# TODO Konsti bitte beschreiben was funktion macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175ddd07-76f5-4bf3-9e53-80f95ccece7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(\n",
    "    directory,\n",
    "    dist_freq=11,\n",
    "    dist_time=3,\n",
    "    time_min_offset=5,\n",
    "    time_max_offset=30,\n",
    "    freq_min_offset=-15,\n",
    "    freq_max_offset=15\n",
    "):\n",
    "    global count\n",
    "    count = 0\n",
    "    \"\"\"\n",
    "    Build a fingerprint database directly from spectrograms using multithreading.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Directory containing audio files.\n",
    "        dist_freq, dist_time (int): Constellation map neighborhood parameters.\n",
    "        time_min_offset, time_max_offset, freq_min_offset, freq_max_offset (int): \n",
    "            Bounds for the \"target zone\" around an anchor point.\n",
    "\n",
    "    Returns:\n",
    "        database (defaultdict): {hash: [(track_name, time_offset), ...]}\n",
    "    \"\"\"\n",
    "    tracks = load_filenames(directory)\n",
    "\n",
    "    path_name = \"partial_database_\" + str(dist_freq) + \"#\" + str(dist_time) + \"#\" + str(time_min_offset) + \"#\" + str(time_max_offset) + \"#\" + str(freq_min_offset) + \"#\" + str(freq_max_offset) + \".pkl\"\n",
    "\n",
    "    # Prepare arguments for each file\n",
    "    args = [\n",
    "        (filename, dist_freq, dist_time, time_min_offset, time_max_offset, freq_min_offset, freq_max_offset) \n",
    "        for filename in tracks\n",
    "    ]\n",
    "    \n",
    "    database = defaultdict(list)\n",
    "    global count2\n",
    "\n",
    "    # Use multithreading to compute hashes for all tracks\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(lambda x: compute_hashes_from_spectrogram(*x), args):\n",
    "            for h, track_name, time_offset in result:\n",
    "                database[h].append((track_name, time_offset))\n",
    "\n",
    "            if(count2 > 1000):\n",
    "                count2 = 0\n",
    "                save_partial_database(database, path_name)\n",
    "                database.clear()\n",
    "    \n",
    "    save_partial_database(database, path_name)\n",
    "    database.clear()\n",
    "    return database\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706ac05-cf86-459b-bc22-ba52a12c4c43",
   "metadata": {},
   "source": [
    "## Hash function\n",
    "This function computes a 32-bit hash, capturing the relationship between an anchor point and a single point within the target zone. The hashing process follows the methodology outlined in the lectures and the Shazam paper, ensuring the hash fits within 32 bits for efficient storage and matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4636f6d5-0fbe-46b6-9222-17b58ab9f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hash(anchor, target):\n",
    "    \"\"\"Generate a 32-bit hash.\"\"\"\n",
    "    f1, t1 = anchor\n",
    "    f2, t2 = target\n",
    "    dt = t2 - t1\n",
    "    return (f1 & 0x3FF) | ((f2 & 0x3FF) << 10) | ((dt & 0xFFF) << 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa57448-1fc0-4039-8108-38f93fef15c1",
   "metadata": {},
   "source": [
    "## Target zone\n",
    "\n",
    "This function identifies and selects points within the target zone of a given anchor point. It determines which points (peaks) from the constellation map fall within the specified bounds and returns all points that meet this criterion. For improved efficiency in identifying points within the target zone, the input point_list is expected to be sorted by time. This sorting allows the function to terminate early when encountering points that are too far in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2067f6-84be-431a-913b-0cec6237fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_zone_points(anchor, point_list,\n",
    "                           time_min_offset, time_max_offset,\n",
    "                           freq_min_offset, freq_max_offset):\n",
    "    \"\"\"\n",
    "    Finds points in 'point_list' that lie within time [t1 + time_min_offset, t1 + time_max_offset]\n",
    "    and frequency [f1 + freq_min_offset, f1 + freq_max_offset].\n",
    "    \n",
    "    anchor: (f1, t1) or (t1, f1) â whichever convention you are using.\n",
    "    point_list: list of (f, t) or (t, f) â must be sorted by the time coordinate as we want to break early.\n",
    "    time_min_offset, time_max_offset: how far in time we look relative to anchor's time t1.\n",
    "    freq_min_offset, freq_max_offset: how far in frequency we look relative to anchor's freq f1.\n",
    "    \"\"\"\n",
    "    f1, t1 = anchor\n",
    "    \n",
    "    # Time bounds\n",
    "    t_min = t1 + time_min_offset\n",
    "    t_max = t1 + time_max_offset\n",
    "    \n",
    "    # Frequency bounds\n",
    "    f_min = f1 + freq_min_offset\n",
    "    f_max = f1 + freq_max_offset\n",
    "    \n",
    "    target_zone_points = []\n",
    "    for (f2, t2) in point_list:\n",
    "        # If the list is sorted by time and t2 > t_max, we can break early.\n",
    "        if t2 > t_max:\n",
    "            break\n",
    "        \n",
    "        if t_min < t2 <= t_max and f_min <= f2 <= f_max:\n",
    "            target_zone_points.append((f2, t2))\n",
    "    \n",
    "    return target_zone_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6799d5b-cde8-4df1-931d-cc27fdc22b00",
   "metadata": {},
   "source": [
    "## Extract id from filename\n",
    "\n",
    "Simple helpfer function to extract the id from filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3fd158-c0ba-461c-95f1-ecec90d31fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def extract_numeric_id(filename):\n",
    "    \"\"\"\n",
    "    Example: \n",
    "      - 'queries/1269810_original.mp3' => '1269810'\n",
    "      - 'tracks/1269810.mp3'           => '1269810'\n",
    "    Adjust to your naming conventions as needed.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48e5d0-2a5a-4b50-bcd1-845f60a40c80",
   "metadata": {},
   "source": [
    "## Matching a single query\n",
    "\n",
    "In this implementation, we created a function, find_best_match_for_query, to match a single query audio track against a database of audio fingerprints. Following the method outlined in the Shazam paper for audio fingerprinting, we utilized a combination of hashing and offset analysis to identify the most likely match. Here's what we did step-by-step:\n",
    "\n",
    "1. **Extract Query Features**:\n",
    "We started by converting the spectrogram of the query track (represented as a 2D Boolean array, cmap) into a list of (frequency, time) points where the spectrogram is non-zero. These points represent prominent features in the audio.\n",
    "\n",
    "2. **Target Zone Generation**:\n",
    "For each anchor point in the query, we defined a \"target zone\" in the spectrogram, constrained by frequency and time offsets (time_min_offset, time_max_offset, freq_min_offset, and freq_max_offset). This allowed us to identify significant relationships between anchor points and their neighbors.\n",
    "\n",
    "3. **Hash Calculation**:\n",
    "We generated unique hashes for pairs of anchor and target points in the query. These hashes encapsulate the relationship between points in terms of time and frequency, enabling robust matching against the database.\n",
    "\n",
    "4. **Database Lookup**:\n",
    "For each hash, we checked if it exists in the database. If found, we retrieved the corresponding track and time offset information from the database. This step is crucial as it allows us to correlate features in the query with precomputed features in the database.\n",
    "\n",
    "5. **Offset Analysis**:\n",
    "We grouped the matches by track name and analyzed their time offsets (delta values between query points and database points). For each track, we tracked how many points matched at the same offset, which is a key indicator of a correct match.\n",
    "\n",
    "6. **Best Match Identification**:\n",
    "Finally, we identified the track with the highest number of consistent matches (i.e., the highest count of points matching at the same offset). This track was returned as the best match, along with the corresponding offset and match count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e7874a6-1d57-42a5-b18e-eef2fd2a243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match_for_query(\n",
    "    query_name,\n",
    "    cmap,\n",
    "    database,\n",
    "    time_min_offset=5,\n",
    "    time_max_offset=30,\n",
    "    freq_min_offset=-15,\n",
    "    freq_max_offset=15\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a query's spectrogram cmap (2D Boolean array),\n",
    "    find the best matching track in the database of fingerprints.\n",
    "\n",
    "    Returns:\n",
    "        best_track: str or None\n",
    "        best_delta: int or None\n",
    "        best_count: int\n",
    "        point_list: list of non-zero (freq,time) points in the query\n",
    "    \"\"\"\n",
    "    # Convert the boolean array to a list of points (freq, time)\n",
    "    point_list = sorted(np.argwhere(cmap).tolist(), key=lambda x: x[1])\n",
    "\n",
    "    # Dictionary of track_name -> (offset -> count)\n",
    "    matches = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # For each point in the query, find matching points in the database\n",
    "    for anchor in point_list:\n",
    "        target_points = get_target_zone_points(\n",
    "            anchor,\n",
    "            point_list,\n",
    "            time_min_offset=time_min_offset,\n",
    "            time_max_offset=time_max_offset,\n",
    "            freq_min_offset=freq_min_offset,\n",
    "            freq_max_offset=freq_max_offset\n",
    "        )\n",
    "\n",
    "        for target_point in target_points:\n",
    "            h = compute_hash(anchor, target_point)\n",
    "\n",
    "            # If our hash is found in the database\n",
    "            if h in database:\n",
    "                # database[h] = list of (track_name, track_offset)\n",
    "                for track_name, track_offset in database[h]:\n",
    "                    delta_offset = track_offset - anchor[1]\n",
    "                    matches[track_name][delta_offset] += 1\n",
    "    \n",
    "    # Find the best match with the highest count\n",
    "    best_track = None\n",
    "    best_delta = None\n",
    "    best_count = 0\n",
    "    \n",
    "    for track_name, offset_counts in matches.items():\n",
    "        for delta_offset, count in offset_counts.items():\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_track = track_name\n",
    "                best_delta = delta_offset\n",
    "\n",
    "    return best_track, best_delta, best_count, point_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b00de-8d06-4940-b52b-ccb1e0be02cf",
   "metadata": {},
   "source": [
    "# TODO Brauchen wir das noch???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb364987-8706-4dc9-9c89-cdce29db2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_chunks_from_pickle(filename):\n",
    "    \"\"\"Load all chunks from a single pickle file into memory.\"\"\"\n",
    "    chunks = []\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                chunks.append(pickle.load(f))  # Load each chunk and append to the list\n",
    "            except EOFError:\n",
    "                break  # Stop when end of file is reached\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a037d6a-5b53-4fcf-af9c-8289d459deb7",
   "metadata": {},
   "source": [
    "# TODO KONSTI bitte deine funktion erklÃ¤ren. ErklÃ¤re dass wir fÃ¼r das upscalen die chunks brauchen, wegen effizienz und so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0451243-5d8d-4340-ad90-ea8ffb42f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_queries_with_chunks(\n",
    "    directory,\n",
    "    dist_freq=11,\n",
    "    dist_time=3,\n",
    "    time_min_offset=5,\n",
    "    time_max_offset=30,\n",
    "    freq_min_offset=-15,\n",
    "    freq_max_offset=15\n",
    "):\n",
    "    \"\"\"\n",
    "    Match queries against a database loaded incrementally in chunks.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the query files.\n",
    "        database_file (str): Path to the serialized database file.\n",
    "        time_min_offset, time_max_offset, freq_min_offset, freq_max_offset (int): \n",
    "            Bounds for matching.\n",
    "\n",
    "    Returns:\n",
    "        results (list): List of query match results.\n",
    "    \"\"\"\n",
    "    database_file = \"partial_database_\" + str(dist_freq) + \"#\" + str(dist_time) + \"#\" + str(time_min_offset) + \"#\" + str(time_max_offset) + \"#\" + str(freq_min_offset) + \"#\" + str(freq_max_offset) + \".pkl\"\n",
    "    queries = load_filenames(directory)  # Load all query filenames\n",
    "    results = []\n",
    "    num_correct = 0\n",
    "    total_queries = len(queries)\n",
    "    \n",
    "    cmaps = {}\n",
    "    \n",
    "    for query_name in queries:\n",
    "        _, cmap = compute_constellation_map_single((query_name, 11, 3))\n",
    "        cmaps[query_name]=cmap\n",
    "\n",
    "    bestmatches = {}\n",
    "    for database_chunk in load_partial_database(database_file):\n",
    "        for query_name in queries:\n",
    "            start = time.time()\n",
    "            track, delta, count, points = find_best_match_for_query(\n",
    "                query_name,\n",
    "                cmaps[query_name],\n",
    "                database_chunk,\n",
    "                time_min_offset=time_min_offset,\n",
    "                time_max_offset=time_max_offset,\n",
    "                freq_min_offset=freq_min_offset,\n",
    "                freq_max_offset=freq_max_offset\n",
    "            )\n",
    "            if query_name in bestmatches: \n",
    "                if bestmatches[query_name][2] < count:\n",
    "                    end = time.time()\n",
    "                    d = (end - start) * 1000\n",
    "                    d = d + bestmatches[query_name][4]\n",
    "                    bestmatches[query_name] = track, delta, count, points, d\n",
    "            else: \n",
    "                end = time.time()\n",
    "                d = (end - start) * 1000\n",
    "                bestmatches[query_name] = track, delta, count, points, d\n",
    "\n",
    "\n",
    "\n",
    "    # Print final results\n",
    "    count3 = 0\n",
    "    total_time = 0.0  # To accumulate the total time\n",
    "    time_count = 0  # To count the number of time values\n",
    "\n",
    "    for query_name in queries:\n",
    "        track_id, _, _, _, d = bestmatches[query_name]  # Unpack values, d is the time\n",
    "        is_match = int(extract_numeric_id(query_name)) == track_id  # Check if IDs match\n",
    "\n",
    "        # Extract numeric time from string (e.g., \"1.23s\" -> 1.23)\n",
    "        total_time += d  # Add to total time\n",
    "        time_count += 1  # Increment the count for time\n",
    "\n",
    "        if is_match:\n",
    "            count3 += 1\n",
    "        # Print query, track ID, match status, and time\n",
    "        print(f\"Query: {query_name}, Track ID: {track_id}, Match: {is_match}, Time: {d}\")\n",
    "\n",
    "    # Calculate the average time\n",
    "    average_time = total_time / time_count if time_count > 0 else 0\n",
    "\n",
    "    # Print the final count and average time\n",
    "    print(f\"Count3: {count3}\")\n",
    "    print(f\"Average Time: {average_time:.2f}s\")\n",
    "\n",
    "    return bestmatches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3bf17-d9e9-4a00-8e6e-b950e049fd7d",
   "metadata": {},
   "source": [
    "# TODO Konsti bitte funktion erklÃ¤ren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b042d3-89d4-45f3-a518-36663b327801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_partial_database(filename):\n",
    "    \"\"\"Load chunks from a pickle file incrementally.\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield pickle.load(f)  # Yield one chunk at a time\n",
    "            except EOFError:\n",
    "                break  # Stop when end of file is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab755dbf-72dc-404e-ae20-871eb9d592cf",
   "metadata": {},
   "source": [
    "# TODO Kann man match_queris lÃ¶schen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8fa4b0-274a-4f67-b712-017a5dee45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_queries(\n",
    "    directory,\n",
    "    database,\n",
    "    time_min_offset=5,\n",
    "    time_max_offset=30,\n",
    "    freq_min_offset=-15,\n",
    "    freq_max_offset=15\n",
    "):\n",
    "    \"\"\"\n",
    "    - Matches each query in cmaps_Q to the best track in the database.\n",
    "    :param cmaps_Q: dict {query_name: 2D numpy array (spectrogram boolean map)}\n",
    "    :param database: dict {hash: [(track_name, track_offset), ...]}\n",
    "    \"\"\"\n",
    "\n",
    "    queries = load_filenames(directory) # load all track filenames\n",
    "        \n",
    "    results = []\n",
    "    num_correct = 0\n",
    "    \n",
    "    # Collect queries in a list to iterate consistently\n",
    "    total_queries = len(queries)\n",
    "\n",
    "    \n",
    "\n",
    "    for query_name in queries:\n",
    "        starttime = time.time()\n",
    "        \n",
    "        _, cmap = compute_constellation_map_single((query_name, 11, 3))       \n",
    "\n",
    "        best_track = None\n",
    "        best_delta = None\n",
    "        best_count = 0\n",
    "        point_list = []\n",
    "        \n",
    "        for database_chunk in load_partial_database(database_file):\n",
    "            track, delta, count, points = find_best_match_for_query(\n",
    "                query_name,\n",
    "                cmap,\n",
    "                database_chunk,\n",
    "                time_min_offset=time_min_offset,\n",
    "                time_max_offset=time_max_offset,\n",
    "                freq_min_offset=freq_min_offset,\n",
    "                freq_max_offset=freq_max_offset\n",
    "            )\n",
    "\n",
    "            # Update the best match if this chunk has a better match\n",
    "            if count > best_count:\n",
    "                best_track, best_delta, best_count, point_list = track, delta, count, points\n",
    "\n",
    "\n",
    "        endtime = time.time()\n",
    "        \n",
    "\n",
    "        query_id = extract_numeric_id(query_name)\n",
    "        track_id = extract_numeric_id(best_track) if best_track else None\n",
    "        correct = (query_id == track_id)\n",
    "        if correct:\n",
    "            num_correct += 1\n",
    "\n",
    "        # Store the result\n",
    "        results.append((query_name, best_track, best_delta, best_count, correct, (endtime-starttime)*1000))\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Print final results\n",
    "    # ----------------------------------------------------------------------\n",
    "    accuracy = num_correct / total_queries if total_queries else 0\n",
    "    print(\"\\nMATCHING RESULTS:\")\n",
    "    sum_duration = 0\n",
    "    for qname, tname, offset, count, is_correct, duration in results:\n",
    "        print(f\"Query: {qname} => Best match: {tname}, Time: {duration} ms, Offset: {offset}, Count: {count}, Correct: {is_correct}\")\n",
    "        sum_duration += duration\n",
    "\n",
    "    print(f\"\\nCorrect matches: {num_correct}/{total_queries}\")\n",
    "    print(f\"Average query time: {sum_duration/len(results)} ms\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4ed7a-b656-4a64-9096-080152d7f08f",
   "metadata": {},
   "source": [
    "# beschreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb22459-1b56-4506-ba7b-2b617fec7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_partial_database(database, filename):\n",
    "    \"\"\"Append partial data to a pickle file.\"\"\"\n",
    "    with open(filename, \"ab\") as f:  # Append mode\n",
    "        pickle.dump(database, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9cf99-83c1-4495-aa81-895789d3c546",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "In the earlier sections, we explained many of the helper functions used in this implementation (Tasks 1-3). Here, we focus on executing these functions effectively within our matching process.\n",
    "\n",
    "As described in the assignment, we use the configuration from Milestone 2.1 to compute the constellation maps. Now, we define **four new configurations for the target zone parameters**. These configurations were tested extensively, first on a small dataset to fine-tune the parameters, and later scaled up to evaluate performance on a larger dataset of 60 tarballs.\n",
    "\n",
    "When defining the target zones, the size of the zone plays a critical role. Larger zones result in more hashes being computed for each track, which increases memory usage, processing time, and query-matching overhead. To balance these trade-offs, we opted for smaller target zones, which provide efficient matching without significantly compromising accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6e30e-bdb3-4691-9050-a712fcf7b579",
   "metadata": {},
   "source": [
    "## Define configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cecf6808-828d-4ea2-9133-8fa244391291",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_1 = {\n",
    "    \"time_min_offset\": 0,\n",
    "    \"time_max_offset\": 50,\n",
    "    \"freq_min_offset\": -10,\n",
    "    \"freq_max_offset\": 30\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    \"time_min_offset\": 0,\n",
    "    \"time_max_offset\": 30,\n",
    "    \"freq_min_offset\": 0,\n",
    "    \"freq_max_offset\": 25\n",
    "}\n",
    "\n",
    "config_3 = {\n",
    "    \"time_min_offset\": 10,\n",
    "    \"time_max_offset\": 40,\n",
    "    \"freq_min_offset\": -20,\n",
    "    \"freq_max_offset\": 20\n",
    "}\n",
    "\n",
    "config_4 = {\n",
    "    \"time_min_offset\": 10,\n",
    "    \"time_max_offset\": 60,\n",
    "    \"freq_min_offset\": -20,\n",
    "    \"freq_max_offset\": 20\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554b41e-ef1f-446d-aa7e-19af3ccba652",
   "metadata": {},
   "source": [
    "## Build the database\n",
    "\n",
    "In this section, we construct the databases required for our audio identification system. The dataset consists of 60 tarballs containing approximately 33,000 tracks. We build a separate database for each of the four target zone configurations defined earlier.\n",
    "\n",
    "To improve efficiency and avoid recalculating the database and hashes each time we run this notebook, we save the constructed databases to binary files using pickle. This ensures persistence while allowing us to reuse the databases seamlessly in subsequent runs.\n",
    "\n",
    "For a detailed explanation of the build_database function and its implementation, refer to the earlier section where it is defined.\n",
    "\n",
    "By creating distinct databases for each configuration, we can experiment with and evaluate the impact of different target zone parameters on performance, accuracy, and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b7e400-1f3b-4327-89ab-6d64f32c6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 tracks\n",
      "Processed 2000 tracks\n",
      "Processed 3000 tracks\n",
      "Processed 4000 tracks\n",
      "Processed 5000 tracks\n",
      "Processed 6000 tracks\n",
      "Processed 7000 tracks\n",
      "Processed 8000 tracks\n",
      "Processed 9000 tracks\n",
      "Processed 10000 tracks\n",
      "Processed 11000 tracks\n",
      "Processed 12000 tracks\n",
      "Processed 13000 tracks\n",
      "Processed 14000 tracks\n",
      "Processed 15000 tracks\n",
      "Processed 16000 tracks\n",
      "Processed 17000 tracks\n",
      "Processed 18000 tracks\n",
      "Processed 19000 tracks\n",
      "Processed 20000 tracks\n",
      "Processed 21000 tracks\n",
      "Processed 22000 tracks\n",
      "Processed 23000 tracks\n",
      "Processed 24000 tracks\n",
      "Processed 25000 tracks\n",
      "Processed 26000 tracks\n",
      "Processed 27000 tracks\n",
      "Processed 28000 tracks\n",
      "Processed 29000 tracks\n",
      "Processed 30000 tracks\n",
      "Processed 31000 tracks\n",
      "Processed 32000 tracks\n",
      "Processed 33000 tracks\n",
      "2438.1496403217316\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "database_1 = build_database(\"tracks\", **config_1)\n",
    "e = time.time()\n",
    "print(f\"Building the database took {e-s} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f147d027-522b-48dd-8507-797722ff18ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114474/1732219511.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tracks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'config_2' is not defined"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "database_2 = build_database(\"tracks\", **config_2)\n",
    "e = time.time()\n",
    "print(f\"Building the database took {e-s} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a946fddc-2a3b-4edd-9166-fe1337b3a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 tracks\n",
      "Processed 2000 tracks\n",
      "Processed 3000 tracks\n",
      "Processed 4000 tracks\n",
      "Processed 5000 tracks\n",
      "Processed 6000 tracks\n",
      "Processed 7000 tracks\n",
      "Processed 8000 tracks\n",
      "Processed 9000 tracks\n",
      "Processed 10000 tracks\n",
      "Processed 11000 tracks\n",
      "Processed 12000 tracks\n",
      "Processed 13000 tracks\n",
      "Processed 14000 tracks\n",
      "Processed 15000 tracks\n",
      "Processed 16000 tracks\n",
      "Processed 17000 tracks\n",
      "Processed 18000 tracks\n",
      "Processed 19000 tracks\n",
      "Processed 20000 tracks\n",
      "Processed 21000 tracks\n",
      "Processed 22000 tracks\n",
      "Processed 23000 tracks\n",
      "Processed 24000 tracks\n",
      "Processed 25000 tracks\n",
      "Processed 26001 tracks\n",
      "Processed 27000 tracks\n",
      "Processed 28000 tracks\n",
      "Processed 29000 tracks\n",
      "Processed 30000 tracks\n",
      "Processed 31000 tracks\n",
      "Processed 32000 tracks\n",
      "Processed 33000 tracks\n",
      "2361.0693411827087\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "database_3 = build_database(\"tracks\", **config_3)\n",
    "e = time.time()\n",
    "print(f\"Building the database took {e-s} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70fc4578-d745-4daf-90ea-07a53c3dcd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 tracks\n",
      "Processed 2001 tracks\n",
      "Processed 3000 tracks\n",
      "Processed 4000 tracks\n",
      "Processed 5000 tracks\n",
      "Processed 6000 tracks\n",
      "Processed 7000 tracks\n",
      "Processed 8000 tracks\n",
      "Processed 9000 tracks\n",
      "Processed 10000 tracks\n",
      "Processed 11000 tracks\n",
      "Processed 12000 tracks\n",
      "Processed 13000 tracks\n",
      "Processed 14000 tracks\n",
      "Processed 15000 tracks\n",
      "Processed 16000 tracks\n",
      "Processed 17000 tracks\n",
      "Processed 18000 tracks\n",
      "Processed 19000 tracks\n",
      "Processed 20000 tracks\n",
      "Processed 21000 tracks\n",
      "Processed 22000 tracks\n",
      "Processed 23000 tracks\n",
      "Processed 24000 tracks\n",
      "Processed 25000 tracks\n",
      "Processed 26000 tracks\n",
      "Processed 27000 tracks\n",
      "Processed 28000 tracks\n",
      "Processed 29000 tracks\n",
      "Processed 30001 tracks\n",
      "Processed 31000 tracks\n",
      "Processed 32000 tracks\n",
      "Processed 33000 tracks\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "database_4 = build_database(\"tracks\", **config_4)\n",
    "e = time.time()\n",
    "print(f\"Building the database took {e-s} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a01437-7b86-49f8-94df-b8bcc61367a2",
   "metadata": {},
   "source": [
    "# Task 2: Audio Identification and Task 3: Scale up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af7584-0c94-4a61-a1fe-b8d893ec6ccb",
   "metadata": {},
   "source": [
    "In this section, we evaluate how well our matching algorithm performs across the four target zone configurations. We test the algorithm by attempting to match a set of query tracks against the corresponding tracks in the database.\n",
    "\n",
    "As described earlier, the matching process works by generating hashes for the query track using the same configuration that was used to construct the database. These query hashes are then compared against the database hashes to find the best match.\n",
    "\n",
    "To optimize memory usage during the matching process, we use a hybrid approach: part of the database is kept in memory, while the rest is stored offline and loaded in chunks as needed. This ensures efficient matching even with the large-scale dataset of 33,000 tracks.\n",
    "\n",
    "The evaluation is conducted using the four previously created databases, each representing one of the configurations. This allows us to analyze the effectiveness of different target zone parameters and assess their impact on query matching accuracy and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "554723cb-6157-45c4-a28b-20f1e2da7f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: queries/1192210_noise.mp3, Track ID: 1192210, Match: True, Time: 4899.5232582092285\n",
      "Query: queries/91810_coding.mp3, Track ID: 91810, Match: True, Time: 60.437679290771484\n",
      "Query: queries/1084710_original.mp3, Track ID: 1084710, Match: True, Time: 155.40218353271484\n",
      "Query: queries/242610_mobile.mp3, Track ID: 900733, Match: False, Time: 25.046586990356445\n",
      "Query: queries/53310_original.mp3, Track ID: 53310, Match: True, Time: 264.6794319152832\n",
      "Query: queries/1192210_mobile.mp3, Track ID: 1192210, Match: True, Time: 42.215585708618164\n",
      "Query: queries/1147910_mobile.mp3, Track ID: 1362117, Match: False, Time: 31.372547149658203\n",
      "Query: queries/242610_noise.mp3, Track ID: 242610, Match: True, Time: 197.79610633850098\n",
      "Query: queries/152310_mobile.mp3, Track ID: 152310, Match: True, Time: 133.58187675476074\n",
      "Query: queries/1227910_original.mp3, Track ID: 1227910, Match: True, Time: 219.75135803222656\n",
      "Query: queries/963810_noise.mp3, Track ID: 963810, Match: True, Time: 480.56936264038086\n",
      "Query: queries/887210_noise.mp3, Track ID: 887210, Match: True, Time: 118.84593963623047\n",
      "Query: queries/91810_noise.mp3, Track ID: 91810, Match: True, Time: 44.12412643432617\n",
      "Query: queries/1084710_coding.mp3, Track ID: 1084710, Match: True, Time: 229.7067642211914\n",
      "Query: queries/1269810_mobile.mp3, Track ID: 1269810, Match: True, Time: 194.55957412719727\n",
      "Query: queries/1390710_mobile.mp3, Track ID: 1390710, Match: True, Time: 43.81871223449707\n",
      "Query: queries/1400510_noise.mp3, Track ID: 153617, Match: False, Time: 37.91642189025879\n",
      "Query: queries/91810_original.mp3, Track ID: 91810, Match: True, Time: 34.999847412109375\n",
      "Query: queries/1084710_noise.mp3, Track ID: 1084710, Match: True, Time: 189.4083023071289\n",
      "Query: queries/1249910_original.mp3, Track ID: 1249910, Match: True, Time: 59.00144577026367\n",
      "Query: queries/1192210_coding.mp3, Track ID: 1192210, Match: True, Time: 566.3740634918213\n",
      "Query: queries/262010_coding.mp3, Track ID: 262010, Match: True, Time: 77.64935493469238\n",
      "Query: queries/262010_original.mp3, Track ID: 262010, Match: True, Time: 246.06847763061523\n",
      "Query: queries/1390710_noise.mp3, Track ID: 1390710, Match: True, Time: 57.57904052734375\n",
      "Query: queries/1147910_original.mp3, Track ID: 1147910, Match: True, Time: 154.1132926940918\n",
      "Query: queries/219510_noise.mp3, Track ID: 219510, Match: True, Time: 291.379451751709\n",
      "Query: queries/136810_coding.mp3, Track ID: 136810, Match: True, Time: 81.34818077087402\n",
      "Query: queries/1400510_coding.mp3, Track ID: 1400510, Match: True, Time: 40.10772705078125\n",
      "Query: queries/887210_mobile.mp3, Track ID: 887210, Match: True, Time: 138.31305503845215\n",
      "Query: queries/1227910_noise.mp3, Track ID: 1227910, Match: True, Time: 206.16507530212402\n",
      "Query: queries/119410_mobile.mp3, Track ID: 119410, Match: True, Time: 119.39287185668945\n",
      "Query: queries/1269810_original.mp3, Track ID: 1269810, Match: True, Time: 600.4893779754639\n",
      "Query: queries/53310_noise.mp3, Track ID: 53310, Match: True, Time: 78.85503768920898\n",
      "Query: queries/136810_mobile.mp3, Track ID: 136304, Match: False, Time: 78.80520820617676\n",
      "Query: queries/963810_mobile.mp3, Track ID: 963810, Match: True, Time: 216.28522872924805\n",
      "Query: queries/1390710_coding.mp3, Track ID: 1390710, Match: True, Time: 60.52207946777344\n",
      "Query: queries/1400510_mobile.mp3, Track ID: 1271442, Match: False, Time: 24.335145950317383\n",
      "Query: queries/119410_coding.mp3, Track ID: 119410, Match: True, Time: 151.23987197875977\n",
      "Query: queries/219510_original.mp3, Track ID: 219510, Match: True, Time: 375.4262924194336\n",
      "Query: queries/94710_noise.mp3, Track ID: 94710, Match: True, Time: 244.3680763244629\n",
      "Query: queries/963810_original.mp3, Track ID: 963810, Match: True, Time: 327.8329372406006\n",
      "Query: queries/1192210_original.mp3, Track ID: 1192210, Match: True, Time: 114.38369750976562\n",
      "Query: queries/152310_coding.mp3, Track ID: 152310, Match: True, Time: 191.88952445983887\n",
      "Query: queries/94710_original.mp3, Track ID: 94710, Match: True, Time: 258.06140899658203\n",
      "Query: queries/219510_mobile.mp3, Track ID: 1284439, Match: False, Time: 66.32852554321289\n",
      "Query: queries/810_coding.mp3, Track ID: 810, Match: True, Time: 331.55226707458496\n",
      "Query: queries/91810_mobile.mp3, Track ID: 91810, Match: True, Time: 107.80692100524902\n",
      "Query: queries/810_noise.mp3, Track ID: 810, Match: True, Time: 261.1844539642334\n",
      "Query: queries/219510_coding.mp3, Track ID: 219510, Match: True, Time: 231.86802864074707\n",
      "Query: queries/1400510_original.mp3, Track ID: 1400510, Match: True, Time: 47.00040817260742\n",
      "Query: queries/1227910_mobile.mp3, Track ID: 37235, Match: False, Time: 897.8333473205566\n",
      "Query: queries/810_original.mp3, Track ID: 810, Match: True, Time: 232.8054904937744\n",
      "Query: queries/152310_noise.mp3, Track ID: 152310, Match: True, Time: 154.6785831451416\n",
      "Query: queries/1269810_noise.mp3, Track ID: 1269810, Match: True, Time: 506.850004196167\n",
      "Query: queries/53310_coding.mp3, Track ID: 53310, Match: True, Time: 42.11568832397461\n",
      "Query: queries/1249910_mobile.mp3, Track ID: 1249910, Match: True, Time: 154.39820289611816\n",
      "Query: queries/94710_coding.mp3, Track ID: 94710, Match: True, Time: 205.68108558654785\n",
      "Query: queries/1390710_original.mp3, Track ID: 1390710, Match: True, Time: 65.35148620605469\n",
      "Query: queries/53310_mobile.mp3, Track ID: 53310, Match: True, Time: 98.09541702270508\n",
      "Query: queries/1249910_coding.mp3, Track ID: 1249910, Match: True, Time: 145.7540988922119\n",
      "Query: queries/152310_original.mp3, Track ID: 152310, Match: True, Time: 174.10755157470703\n",
      "Query: queries/242610_coding.mp3, Track ID: 242610, Match: True, Time: 196.5622901916504\n",
      "Query: queries/262010_noise.mp3, Track ID: 262010, Match: True, Time: 252.18582153320312\n",
      "Query: queries/1269810_coding.mp3, Track ID: 1269810, Match: True, Time: 575.6409168243408\n",
      "Query: queries/1147910_coding.mp3, Track ID: 1147910, Match: True, Time: 156.04496002197266\n",
      "Query: queries/119410_original.mp3, Track ID: 119410, Match: True, Time: 121.21343612670898\n",
      "Query: queries/810_mobile.mp3, Track ID: 1093545, Match: False, Time: 159.7728729248047\n",
      "Query: queries/119410_noise.mp3, Track ID: 119410, Match: True, Time: 131.6661834716797\n",
      "Query: queries/887210_original.mp3, Track ID: 887210, Match: True, Time: 126.26171112060547\n",
      "Query: queries/1084710_mobile.mp3, Track ID: 321050, Match: False, Time: 8.042097091674805\n",
      "Query: queries/1147910_noise.mp3, Track ID: 1147910, Match: True, Time: 151.43370628356934\n",
      "Query: queries/136810_original.mp3, Track ID: 136810, Match: True, Time: 102.44202613830566\n",
      "Query: queries/887210_coding.mp3, Track ID: 887210, Match: True, Time: 147.12905883789062\n",
      "Query: queries/1249910_noise.mp3, Track ID: 1249910, Match: True, Time: 154.86693382263184\n",
      "Query: queries/94710_mobile.mp3, Track ID: 94710, Match: True, Time: 221.68779373168945\n",
      "Query: queries/262010_mobile.mp3, Track ID: 354914, Match: False, Time: 33.6148738861084\n",
      "Query: queries/242610_original.mp3, Track ID: 242610, Match: True, Time: 121.02746963500977\n",
      "Query: queries/136810_noise.mp3, Track ID: 136810, Match: True, Time: 105.32045364379883\n",
      "Query: queries/1227910_coding.mp3, Track ID: 1227910, Match: True, Time: 186.77496910095215\n",
      "Query: queries/963810_coding.mp3, Track ID: 963810, Match: True, Time: 513.2541656494141\n",
      "Count3: 70\n",
      "Average Time: 241.90s\n",
      "222.18148946762085\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "matches_1 = match_queries_with_chunks(\"queries\", **config_1)\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dac8dd84-c409-4f64-a133-d9f7309884b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: queries/1192210_noise.mp3, Track ID: 1192210, Match: True, Time: 52.24132537841797\n",
      "Query: queries/91810_coding.mp3, Track ID: 91810, Match: True, Time: 26.519775390625\n",
      "Query: queries/1084710_original.mp3, Track ID: 1084710, Match: True, Time: 110.30721664428711\n",
      "Query: queries/242610_mobile.mp3, Track ID: 1262645, Match: False, Time: 23.451566696166992\n",
      "Query: queries/53310_original.mp3, Track ID: 53310, Match: True, Time: 38.89894485473633\n",
      "Query: queries/1192210_mobile.mp3, Track ID: 1192210, Match: True, Time: 506.13999366760254\n",
      "Query: queries/1147910_mobile.mp3, Track ID: 173343, Match: False, Time: 511.0750198364258\n",
      "Query: queries/242610_noise.mp3, Track ID: 242610, Match: True, Time: 167.97804832458496\n",
      "Query: queries/152310_mobile.mp3, Track ID: 152310, Match: True, Time: 42.971134185791016\n",
      "Query: queries/1227910_original.mp3, Track ID: 1227910, Match: True, Time: 715.6801223754883\n",
      "Query: queries/963810_noise.mp3, Track ID: 963810, Match: True, Time: 219.14100646972656\n",
      "Query: queries/887210_noise.mp3, Track ID: 887210, Match: True, Time: 50.03476142883301\n",
      "Query: queries/91810_noise.mp3, Track ID: 91810, Match: True, Time: 28.98097038269043\n",
      "Query: queries/1084710_coding.mp3, Track ID: 1084710, Match: True, Time: 177.10113525390625\n",
      "Query: queries/1269810_mobile.mp3, Track ID: 1269810, Match: True, Time: 103.71994972229004\n",
      "Query: queries/1390710_mobile.mp3, Track ID: 1390710, Match: True, Time: 28.4273624420166\n",
      "Query: queries/1400510_noise.mp3, Track ID: 1418110, Match: False, Time: 23.183822631835938\n",
      "Query: queries/91810_original.mp3, Track ID: 91810, Match: True, Time: 51.48005485534668\n",
      "Query: queries/1084710_noise.mp3, Track ID: 1084710, Match: True, Time: 127.25186347961426\n",
      "Query: queries/1249910_original.mp3, Track ID: 1249910, Match: True, Time: 60.93645095825195\n",
      "Query: queries/1192210_coding.mp3, Track ID: 1192210, Match: True, Time: 56.69736862182617\n",
      "Query: queries/262010_coding.mp3, Track ID: 262010, Match: True, Time: 52.42419242858887\n",
      "Query: queries/262010_original.mp3, Track ID: 262010, Match: True, Time: 129.55355644226074\n",
      "Query: queries/1390710_noise.mp3, Track ID: 1390710, Match: True, Time: 35.93635559082031\n",
      "Query: queries/1147910_original.mp3, Track ID: 1147910, Match: True, Time: 61.553955078125\n",
      "Query: queries/219510_noise.mp3, Track ID: 219510, Match: True, Time: 332.7467441558838\n",
      "Query: queries/136810_coding.mp3, Track ID: 136810, Match: True, Time: 77.75092124938965\n",
      "Query: queries/1400510_coding.mp3, Track ID: 1400510, Match: True, Time: 16.388654708862305\n",
      "Query: queries/887210_mobile.mp3, Track ID: 887210, Match: True, Time: 50.44364929199219\n",
      "Query: queries/1227910_noise.mp3, Track ID: 1227910, Match: True, Time: 127.41279602050781\n",
      "Query: queries/119410_mobile.mp3, Track ID: 119410, Match: True, Time: 40.25721549987793\n",
      "Query: queries/1269810_original.mp3, Track ID: 1269810, Match: True, Time: 346.9569683074951\n",
      "Query: queries/53310_noise.mp3, Track ID: 53310, Match: True, Time: 59.4477653503418\n",
      "Query: queries/136810_mobile.mp3, Track ID: 1378007, Match: False, Time: 62.62612342834473\n",
      "Query: queries/963810_mobile.mp3, Track ID: 963810, Match: True, Time: 98.57439994812012\n",
      "Query: queries/1390710_coding.mp3, Track ID: 1390710, Match: True, Time: 42.06109046936035\n",
      "Query: queries/1400510_mobile.mp3, Track ID: 1271442, Match: False, Time: 14.548540115356445\n",
      "Query: queries/119410_coding.mp3, Track ID: 119410, Match: True, Time: 65.48213958740234\n",
      "Query: queries/219510_original.mp3, Track ID: 219510, Match: True, Time: 281.88371658325195\n",
      "Query: queries/94710_noise.mp3, Track ID: 94710, Match: True, Time: 69.1537857055664\n",
      "Query: queries/963810_original.mp3, Track ID: 963810, Match: True, Time: 141.2208080291748\n",
      "Query: queries/1192210_original.mp3, Track ID: 1192210, Match: True, Time: 61.06376647949219\n",
      "Query: queries/152310_coding.mp3, Track ID: 152310, Match: True, Time: 85.16383171081543\n",
      "Query: queries/94710_original.mp3, Track ID: 94710, Match: True, Time: 62.75629997253418\n",
      "Query: queries/219510_mobile.mp3, Track ID: 1009559, Match: False, Time: 36.637306213378906\n",
      "Query: queries/810_coding.mp3, Track ID: 810, Match: True, Time: 216.51935577392578\n",
      "Query: queries/91810_mobile.mp3, Track ID: 91810, Match: True, Time: 33.75077247619629\n",
      "Query: queries/810_noise.mp3, Track ID: 810, Match: True, Time: 126.44219398498535\n",
      "Query: queries/219510_coding.mp3, Track ID: 219510, Match: True, Time: 244.2030906677246\n",
      "Query: queries/1400510_original.mp3, Track ID: 1400510, Match: True, Time: 8.315801620483398\n",
      "Query: queries/1227910_mobile.mp3, Track ID: 37235, Match: False, Time: 152.3292064666748\n",
      "Query: queries/810_original.mp3, Track ID: 810, Match: True, Time: 113.56925964355469\n",
      "Query: queries/152310_noise.mp3, Track ID: 152310, Match: True, Time: 125.22292137145996\n",
      "Query: queries/1269810_noise.mp3, Track ID: 1269810, Match: True, Time: 328.2744884490967\n",
      "Query: queries/53310_coding.mp3, Track ID: 53310, Match: True, Time: 18.015146255493164\n",
      "Query: queries/1249910_mobile.mp3, Track ID: 1249910, Match: True, Time: 90.97433090209961\n",
      "Query: queries/94710_coding.mp3, Track ID: 94710, Match: True, Time: 88.58036994934082\n",
      "Query: queries/1390710_original.mp3, Track ID: 1390710, Match: True, Time: 25.318622589111328\n",
      "Query: queries/53310_mobile.mp3, Track ID: 53310, Match: True, Time: 50.567626953125\n",
      "Query: queries/1249910_coding.mp3, Track ID: 1249910, Match: True, Time: 87.97287940979004\n",
      "Query: queries/152310_original.mp3, Track ID: 152310, Match: True, Time: 157.49835968017578\n",
      "Query: queries/242610_coding.mp3, Track ID: 242610, Match: True, Time: 91.42708778381348\n",
      "Query: queries/262010_noise.mp3, Track ID: 262010, Match: True, Time: 240.07129669189453\n",
      "Query: queries/1269810_coding.mp3, Track ID: 1269810, Match: True, Time: 386.26837730407715\n",
      "Query: queries/1147910_coding.mp3, Track ID: 1147910, Match: True, Time: 62.72125244140625\n",
      "Query: queries/119410_original.mp3, Track ID: 119410, Match: True, Time: 63.20786476135254\n",
      "Query: queries/810_mobile.mp3, Track ID: 1306203, Match: False, Time: 48.68316650390625\n",
      "Query: queries/119410_noise.mp3, Track ID: 119410, Match: True, Time: 71.63715362548828\n",
      "Query: queries/887210_original.mp3, Track ID: 887210, Match: True, Time: 55.31907081604004\n",
      "Query: queries/1084710_mobile.mp3, Track ID: 1310246, Match: False, Time: 14.727592468261719\n",
      "Query: queries/1147910_noise.mp3, Track ID: 1147910, Match: True, Time: 95.75271606445312\n",
      "Query: queries/136810_original.mp3, Track ID: 136810, Match: True, Time: 48.795461654663086\n",
      "Query: queries/887210_coding.mp3, Track ID: 887210, Match: True, Time: 45.343875885009766\n",
      "Query: queries/1249910_noise.mp3, Track ID: 1249910, Match: True, Time: 99.98273849487305\n",
      "Query: queries/94710_mobile.mp3, Track ID: 13910, Match: False, Time: 74.00131225585938\n",
      "Query: queries/262010_mobile.mp3, Track ID: 1368401, Match: False, Time: 6.651878356933594\n",
      "Query: queries/242610_original.mp3, Track ID: 242610, Match: True, Time: 55.93109130859375\n",
      "Query: queries/136810_noise.mp3, Track ID: 136810, Match: True, Time: 73.39096069335938\n",
      "Query: queries/1227910_coding.mp3, Track ID: 1227910, Match: True, Time: 126.6016960144043\n",
      "Query: queries/963810_coding.mp3, Track ID: 963810, Match: True, Time: 232.80000686645508\n",
      "Count3: 69\n",
      "Average Time: 115.44s\n"
     ]
    }
   ],
   "source": [
    "matches_2 = match_queries_with_chunks(\"queries\", **config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f26c43c-047d-4d50-8286-efb526123346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: queries/1192210_noise.mp3, Track ID: 1192210, Match: True, Time: 47.7452278137207\n",
      "Query: queries/91810_coding.mp3, Track ID: 91810, Match: True, Time: 19.625186920166016\n",
      "Query: queries/1084710_original.mp3, Track ID: 1084710, Match: True, Time: 246.81901931762695\n",
      "Query: queries/242610_mobile.mp3, Track ID: 1352901, Match: False, Time: 13.442277908325195\n",
      "Query: queries/53310_original.mp3, Track ID: 53310, Match: True, Time: 18.624305725097656\n",
      "Query: queries/1192210_mobile.mp3, Track ID: 1192210, Match: True, Time: 709.6705436706543\n",
      "Query: queries/1147910_mobile.mp3, Track ID: 1066916, Match: False, Time: 28.91063690185547\n",
      "Query: queries/242610_noise.mp3, Track ID: 242610, Match: True, Time: 101.84335708618164\n",
      "Query: queries/152310_mobile.mp3, Track ID: 152310, Match: True, Time: 82.58891105651855\n",
      "Query: queries/1227910_original.mp3, Track ID: 1227910, Match: True, Time: 145.33519744873047\n",
      "Query: queries/963810_noise.mp3, Track ID: 963810, Match: True, Time: 131.2096118927002\n",
      "Query: queries/887210_noise.mp3, Track ID: 887210, Match: True, Time: 75.592041015625\n",
      "Query: queries/91810_noise.mp3, Track ID: 91810, Match: True, Time: 35.28118133544922\n",
      "Query: queries/1084710_coding.mp3, Track ID: 1084710, Match: True, Time: 142.20285415649414\n",
      "Query: queries/1269810_mobile.mp3, Track ID: 1269810, Match: True, Time: 124.9995231628418\n",
      "Query: queries/1390710_mobile.mp3, Track ID: 1390710, Match: True, Time: 39.504289627075195\n",
      "Query: queries/1400510_noise.mp3, Track ID: 1146535, Match: False, Time: 13.980627059936523\n",
      "Query: queries/91810_original.mp3, Track ID: 91810, Match: True, Time: 24.42336082458496\n",
      "Query: queries/1084710_noise.mp3, Track ID: 1084710, Match: True, Time: 170.9728240966797\n",
      "Query: queries/1249910_original.mp3, Track ID: 1249910, Match: True, Time: 69.08893585205078\n",
      "Query: queries/1192210_coding.mp3, Track ID: 1192210, Match: True, Time: 43.36833953857422\n",
      "Query: queries/262010_coding.mp3, Track ID: 262010, Match: True, Time: 66.46418571472168\n",
      "Query: queries/262010_original.mp3, Track ID: 262010, Match: True, Time: 182.72805213928223\n",
      "Query: queries/1390710_noise.mp3, Track ID: 1390710, Match: True, Time: 34.83176231384277\n",
      "Query: queries/1147910_original.mp3, Track ID: 1147910, Match: True, Time: 76.86018943786621\n",
      "Query: queries/219510_noise.mp3, Track ID: 219510, Match: True, Time: 184.29088592529297\n",
      "Query: queries/136810_coding.mp3, Track ID: 136810, Match: True, Time: 80.49249649047852\n",
      "Query: queries/1400510_coding.mp3, Track ID: 1400510, Match: True, Time: 13.82136344909668\n",
      "Query: queries/887210_mobile.mp3, Track ID: 887210, Match: True, Time: 78.98449897766113\n",
      "Query: queries/1227910_noise.mp3, Track ID: 1227910, Match: True, Time: 88.59372138977051\n",
      "Query: queries/119410_mobile.mp3, Track ID: 119410, Match: True, Time: 71.08521461486816\n",
      "Query: queries/1269810_original.mp3, Track ID: 1269810, Match: True, Time: 226.776123046875\n",
      "Query: queries/53310_noise.mp3, Track ID: 53310, Match: True, Time: 62.00599670410156\n",
      "Query: queries/136810_mobile.mp3, Track ID: 1065626, Match: False, Time: 62.276601791381836\n",
      "Query: queries/963810_mobile.mp3, Track ID: 963810, Match: True, Time: 96.20404243469238\n",
      "Query: queries/1390710_coding.mp3, Track ID: 1390710, Match: True, Time: 55.162668228149414\n",
      "Query: queries/1400510_mobile.mp3, Track ID: 1271442, Match: False, Time: 13.38052749633789\n",
      "Query: queries/119410_coding.mp3, Track ID: 119410, Match: True, Time: 102.86927223205566\n",
      "Query: queries/219510_original.mp3, Track ID: 219510, Match: True, Time: 228.00660133361816\n",
      "Query: queries/94710_noise.mp3, Track ID: 94710, Match: True, Time: 119.12322044372559\n",
      "Query: queries/963810_original.mp3, Track ID: 963810, Match: True, Time: 216.3393497467041\n",
      "Query: queries/1192210_original.mp3, Track ID: 1192210, Match: True, Time: 59.41891670227051\n",
      "Query: queries/152310_coding.mp3, Track ID: 152310, Match: True, Time: 103.0569076538086\n",
      "Query: queries/94710_original.mp3, Track ID: 94710, Match: True, Time: 143.0647373199463\n",
      "Query: queries/219510_mobile.mp3, Track ID: 1064503, Match: False, Time: 26.154279708862305\n",
      "Query: queries/810_coding.mp3, Track ID: 810, Match: True, Time: 164.78586196899414\n",
      "Query: queries/91810_mobile.mp3, Track ID: 91810, Match: True, Time: 48.746585845947266\n",
      "Query: queries/810_noise.mp3, Track ID: 810, Match: True, Time: 86.90786361694336\n",
      "Query: queries/219510_coding.mp3, Track ID: 219510, Match: True, Time: 208.19664001464844\n",
      "Query: queries/1400510_original.mp3, Track ID: 1400510, Match: True, Time: 15.27714729309082\n",
      "Query: queries/1227910_mobile.mp3, Track ID: 1227910, Match: True, Time: 141.82138442993164\n",
      "Query: queries/810_original.mp3, Track ID: 810, Match: True, Time: 103.76262664794922\n",
      "Query: queries/152310_noise.mp3, Track ID: 152310, Match: True, Time: 117.45142936706543\n",
      "Query: queries/1269810_noise.mp3, Track ID: 1269810, Match: True, Time: 229.7065258026123\n",
      "Query: queries/53310_coding.mp3, Track ID: 53310, Match: True, Time: 36.20147705078125\n",
      "Query: queries/1249910_mobile.mp3, Track ID: 1249910, Match: True, Time: 105.26418685913086\n",
      "Query: queries/94710_coding.mp3, Track ID: 94710, Match: True, Time: 131.76202774047852\n",
      "Query: queries/1390710_original.mp3, Track ID: 1390710, Match: True, Time: 561.8500709533691\n",
      "Query: queries/53310_mobile.mp3, Track ID: 53310, Match: True, Time: 57.532548904418945\n",
      "Query: queries/1249910_coding.mp3, Track ID: 1249910, Match: True, Time: 87.41450309753418\n",
      "Query: queries/152310_original.mp3, Track ID: 152310, Match: True, Time: 135.10441780090332\n",
      "Query: queries/242610_coding.mp3, Track ID: 242610, Match: True, Time: 89.62655067443848\n",
      "Query: queries/262010_noise.mp3, Track ID: 262010, Match: True, Time: 314.6224021911621\n",
      "Query: queries/1269810_coding.mp3, Track ID: 1269810, Match: True, Time: 257.1573257446289\n",
      "Query: queries/1147910_coding.mp3, Track ID: 1147910, Match: True, Time: 129.39691543579102\n",
      "Query: queries/119410_original.mp3, Track ID: 119410, Match: True, Time: 107.15007781982422\n",
      "Query: queries/810_mobile.mp3, Track ID: 1052255, Match: False, Time: 67.79026985168457\n",
      "Query: queries/119410_noise.mp3, Track ID: 119410, Match: True, Time: 123.41570854187012\n",
      "Query: queries/887210_original.mp3, Track ID: 887210, Match: True, Time: 96.87685966491699\n",
      "Query: queries/1084710_mobile.mp3, Track ID: 1356534, Match: False, Time: 14.382123947143555\n",
      "Query: queries/1147910_noise.mp3, Track ID: 1147910, Match: True, Time: 59.53407287597656\n",
      "Query: queries/136810_original.mp3, Track ID: 136810, Match: True, Time: 71.90275192260742\n",
      "Query: queries/887210_coding.mp3, Track ID: 887210, Match: True, Time: 74.44500923156738\n",
      "Query: queries/1249910_noise.mp3, Track ID: 1249910, Match: True, Time: 78.34649085998535\n",
      "Query: queries/94710_mobile.mp3, Track ID: 94710, Match: True, Time: 99.82848167419434\n",
      "Query: queries/262010_mobile.mp3, Track ID: 208032, Match: False, Time: 14.393091201782227\n",
      "Query: queries/242610_original.mp3, Track ID: 242610, Match: True, Time: 106.67276382446289\n",
      "Query: queries/136810_noise.mp3, Track ID: 136810, Match: True, Time: 75.26040077209473\n",
      "Query: queries/1227910_coding.mp3, Track ID: 1227910, Match: True, Time: 99.00069236755371\n",
      "Query: queries/963810_coding.mp3, Track ID: 963810, Match: True, Time: 187.78491020202637\n",
      "Count3: 71\n",
      "Average Time: 112.21s\n"
     ]
    }
   ],
   "source": [
    "matches_3 = match_queries_with_chunks(\"queries\", **config_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9f29b-8265-4671-ae62-83e121856485",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_4 = match_queries_with_chunks(\"queries\", **config_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b337a1-8018-4260-b0c7-fd3da5d467f2",
   "metadata": {},
   "source": [
    "# Task 4: Evaluation and Report\n",
    " In this section, we evaluate we compare and visualize our experiments. We evaluate our experiments on various metrics and also show the results visually. Finally, we also summarize our findings and thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209e237-f292-46a3-bdf5-2e78307bad9d",
   "metadata": {},
   "source": [
    "## Time for building each database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b85a6-27c4-42a4-91db-fbeb26a2f071",
   "metadata": {},
   "source": [
    "## Query time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796038fb-a96f-4779-bc74-47725bde0dfc",
   "metadata": {},
   "source": [
    "## Matching Accuracy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93383ff-8d11-4d89-886a-ea24484a6101",
   "metadata": {},
   "source": [
    "## Category Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cc5b5-4549-400c-912e-7ad05e37a397",
   "metadata": {},
   "source": [
    "# Thought process and Final Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
